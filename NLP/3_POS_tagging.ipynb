{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'basic', 'tutorial', 'on', 'POS', 'tagging', '.']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"This is a basic tutorial on POS tagging.\"\n",
    "tokenizedSent = nltk.word_tokenize(sentence)\n",
    "print(tokenizedSent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('basic', 'JJ'), ('tutorial', 'NN'), ('on', 'IN'), ('POS', 'NNP'), ('tagging', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(nltk.pos_tag(tokenizedSent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]\n"
     ]
    }
   ],
   "source": [
    "print(brown.sents()) # Gives me sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('Fulton', 'NNP'), ('County', 'NNP'), ('Grand', 'NNP'), ('Jury', 'NNP'), ('said', 'VBD'), ('Friday', 'NNP'), ('an', 'DT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NNP'), ('recent', 'JJ'), ('primary', 'JJ'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'DT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'IN'), ('any', 'DT'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(nltk.pos_tag(brown.sents()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'need', 'a', 'flight', 'from', 'Atlanta', '.']\n",
      "['Does', 'this', 'flight', 'serve', 'dinner', '.']\n",
      "[('I', 'PRP'), ('need', 'VBP'), ('a', 'DT'), ('flight', 'NN'), ('from', 'IN'), ('Atlanta', 'NNP'), ('.', '.')]\n",
      "[('Does', 'VBZ'), ('this', 'DT'), ('flight', 'NN'), ('serve', 'NN'), ('dinner', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "sentence2 = \"I need a flight from Atlanta.\"\n",
    "sentence3 = \"Does this flight serve dinner.\"\n",
    "tokenizedSent2 = nltk.word_tokenize(sentence2)\n",
    "tokenizedSent3 = nltk.word_tokenize(sentence3)\n",
    "print(tokenizedSent2)\n",
    "print(tokenizedSent3)\n",
    "print(nltk.pos_tag(tokenizedSent2))\n",
    "print(nltk.pos_tag(tokenizedSent3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "146ad12ad804e51233bd8e0e4750bbd5b1ea650c2a554e98761327ccb594fe93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
